<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://flightvin.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://flightvin.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-21T03:56:40+00:00</updated><id>https://flightvin.github.io/feed.xml</id><title type="html">blank</title><subtitle>Vineeth&apos;s webpage. </subtitle><entry><title type="html">Trying to Teach Freshmen Robotics 2</title><link href="https://flightvin.github.io/blog/2025/trying-to-teach-freshmen-robotics-2/" rel="alternate" type="text/html" title="Trying to Teach Freshmen Robotics 2"/><published>2025-02-28T16:00:00+00:00</published><updated>2025-02-28T16:00:00+00:00</updated><id>https://flightvin.github.io/blog/2025/trying-to-teach-freshmen-robotics-2</id><content type="html" xml:base="https://flightvin.github.io/blog/2025/trying-to-teach-freshmen-robotics-2/"><![CDATA[<h2 id="weeks-5-to-8">Weeks 5 to 8</h2> <h3 id="stuff-that-i-sent-over">Stuff that I sent over</h3> <ol> <li>PyTorch</li> <li>Robotic Vision (with OpenCV)</li> </ol> <p>Evidently, progress in the stuff I could teach was slow owing to academics (ironic, isn’t it?). Regardless, they are still interested in RRC and a couple of them got part-time internships in a robotics startup (Yay!).</p> <h3 id="pytorch">PyTorch</h3> <p>Not just the basics but also dive into critical aspects that will be essential for applying neural networks to robotics problems.</p> <ol> <li><strong>Getting Started with PyTorch:</strong> <ul> <li><strong>Resource:</strong> <a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a><br/> Familiarize yourself with the core components of PyTorch.</li> </ul> </li> <li><strong>Data Loaders and Datasets:</strong> <ul> <li>PyTorch’s <code class="language-plaintext highlighter-rouge">torch.utils.data.Dataset</code> and <code class="language-plaintext highlighter-rouge">DataLoader</code> classes are designed to simplify data handling.</li> <li><strong>Key Aspects:</strong> <ul> <li><strong>Custom Datasets:</strong> How to structure and preprocess your robotics data for training.</li> <li><strong>Batching &amp; Shuffling:</strong> Efficiently loading data during training to improve performance.</li> <li><strong>Parallel Data Loading:</strong> Leveraging multi-threading to accelerate your training pipeline.</li> </ul> </li> <li><strong>Resource:</strong> The <a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html">Data Loading Tutorial</a></li> </ul> </li> <li><strong>Optimization Theory:</strong> <ul> <li>Understanding the mathematics and intuition behind optimization is crucial.</li> <li><strong>Focus Areas:</strong> <ul> <li><strong>Gradient Descent and Variants:</strong> Learn why and how different optimizers work (SGD, Adam, etc.).</li> <li><strong>Tuning Hyperparameters:</strong> Experiment with learning rates, momentum, and other parameters through <code class="language-plaintext highlighter-rouge">torch.optim</code>.</li> </ul> </li> <li><strong>Resource:</strong> The <a href="https://pytorch.org/docs/stable/optim.html">PyTorch Optimizers Documentation</a> is a solid starting point.</li> <li><strong>Other stuff:</strong> <ul> <li>You have done quite a bit of this in the mathy bits earlier and will redo it in the mobile robotics course. Take a look again at this in for the time being: <a href="https://web.stanford.edu/group/sisl/k12/optimization/MO-unit1-pdfs/1.1optimization.pdf">Intro to Optimization</a></li> </ul> </li> </ul> </li> </ol> <h3 id="robotic-vision-with-opencv">Robotic Vision with OpenCV</h3> <ol> <li><strong>Introduction to OpenCV:</strong> <ul> <li><strong>Resource:</strong> The <a href="https://docs.opencv.org/master/d6/d00/tutorial_py_root.html">OpenCV-Python Tutorials</a> for an overview.</li> </ul> </li> <li><strong>Multi-view Geometry:</strong> <ul> <li>A super important thing in robotic vision is the ability to perceive depth and spatial relationships using multiple images.</li> <li><strong>Focus Areas:</strong> <ul> <li><strong>Camera Calibration:</strong> Learn to determine intrinsic and extrinsic camera parameters to correct lens distortions. <ul> <li><strong>Resource:</strong> The <a href="https://docs.opencv.org/3.4/dc/dbb/tutorial_py_calibration.html">Camera Calibration Tutorial</a> guides you through this process.</li> </ul> </li> <li><strong>Epipolar Geometry &amp; Stereo Vision:</strong> Understand how to estimate depth and recover 3D information from two or more camera views. <ul> <li><strong>Resource:</strong> <a href="https://www.robots.ox.ac.uk/~vgg/hzbook/">Multi-view Geometry</a> is perhaps the best book available. There are a few copies in the library as well.</li> </ul> </li> </ul> </li> </ul> </li> <li><strong>Robust Vision Pipelines:</strong> <ul> <li><strong>Key Concepts:</strong> <ul> <li><strong>Feature Detection:</strong> Experiment with detectors such as SIFT, SURF, or ORB to recognize and match key points in images.</li> <li><strong>Real-time Processing:</strong> Build pipelines that can handle continuous video streams and process images on the fly.</li> </ul> </li> </ul> </li> </ol> <h4 id="final-things">Final Things</h4> <p>Once you’re done. Start with reading about SLAM pipelines.</p>]]></content><author><name></name></author><category term="robotics"/><category term="IIIT"/><category term="robotics"/><summary type="html"><![CDATA[My introduction to robotics for a few undergrad freshmen]]></summary></entry><entry><title type="html">A project on the GFS</title><link href="https://flightvin.github.io/blog/2024/a-project-on-the-gfs/" rel="alternate" type="text/html" title="A project on the GFS"/><published>2024-12-29T20:56:00+00:00</published><updated>2024-12-29T20:56:00+00:00</updated><id>https://flightvin.github.io/blog/2024/a-project-on-the-gfs</id><content type="html" xml:base="https://flightvin.github.io/blog/2024/a-project-on-the-gfs/"><![CDATA[<p>Essentially, I, along with a collaborator (<a href="https://www.linkedin.com/in/mitansh-kayathwal-888836227/">Mitansh K</a>), did the following -</p> <ol> <li><strong>Localized Implementation:</strong> Implemented pretty much everything that’s offered by the Google File System inclusing <ol> <li>Write</li> <li>Read</li> <li>Replication</li> <li>Record Append</li> <li>Re-Replication</li> <li>Stale Replica Handling</li> <li>Garbage Collection</li> <li>Operation Log</li> <li>Data Integrity</li> </ol> </li> </ol> <p>using a codebase of 7200 LOC in Go. Evidently, we missed out on snapshoting and directory management and have left them as to-dos.</p> <ol> <li> <p><strong>Enhanced Consistency:</strong> Rather than the at-least once record append operations offered by the GFS, we implemented it to be exactly once. This was done using a modified version of the 2PC protocol and handling idempotency (do see our report!).</p> </li> <li> <p><strong>Comprehensive System Analysis:</strong> Validated system performance through extensive benchmarking, demonstrating near-linear scaling in throughput for reads, writes, and appends, while maintaining consistency and reliability.</p> </li> </ol> <p>The implementation could be found <a href="https://github.com/reimagining-gfs/main-repo">here</a> and the report <a href="https://github.com/reimagining-gfs/main-repo/blob/main/report.pdf">here</a>.</p> <p>Any thoughts/improvements (especially on the GitHub issues) would be welcome.</p>]]></content><author><name></name></author><category term="software"/><category term="IIIT"/><category term="systems"/><summary type="html"><![CDATA[Adding exactly-once record append semantics to the Google File System]]></summary></entry><entry><title type="html">Trying to Teach Freshmen Robotics 1</title><link href="https://flightvin.github.io/blog/2024/trying-to-teach-freshmen-robotics-1/" rel="alternate" type="text/html" title="Trying to Teach Freshmen Robotics 1"/><published>2024-12-25T16:40:16+00:00</published><updated>2024-12-25T16:40:16+00:00</updated><id>https://flightvin.github.io/blog/2024/trying-to-teach-freshmen-robotics-1</id><content type="html" xml:base="https://flightvin.github.io/blog/2024/trying-to-teach-freshmen-robotics-1/"><![CDATA[<p><em>Edit</em>: Rephrasing</p> <h2 id="week-1-introduction-and-getting-your-hands-dirty-on-software">Week 1: introduction and getting your hands dirty on software</h2> <p>I recently undertook the task of introducing a bunch of freshmen to robotics. I’ll keep updating this as they progress.</p> <p>Here’s the first email that I had sent to a mentee (with some bits removed).</p> <hr/> <p>A short introduction - I’m Vineeth, a UG4 CSE Honours student under Prof. Madhava Krishna. I’ve worked on Visual Place Recognition, Video Object Detection, Object Identification and Localization, and am currently focused on building a navigation stack (lots of robotics terms - you’ll learn them as you go).</p> <p>Considering that you probably won’t be doing courses such as DASS and ISS (<em>some introductory courses for CS majors at IIIT on software</em>) that give you a glance into Software Engineering, and since it is vital part of running any experiment successfully, I would like to get you started off with reading the following (skim, don’t go much in-depth):</p> <ol> <li>An Introduction to Abstraction (<a href="https://www.lesswrong.com/posts/CHSBRLWY5bzZdchFF/a-thorough-introduction-to-abstraction">link</a>)</li> <li>Writing Modular Code (<a href="https://best-practice-and-impact.github.io/qa-of-code-guidance/modular_code.html">link</a>)</li> <li>Python for Research (<a href="https://rits.github-pages.ucl.ac.uk/doctoral-programming-intro/">link</a>, please skim this - see the headings and figure out whether you know the general information in it)</li> </ol> <p>I expect this to take 2-3 days at most, and will then give you resources for:</p> <ol> <li>ROS (Please dual boot with Ubuntu 20 for this; If you use some other Linux Distro, check compatibility)</li> <li>Basic Optimization Theory (Brush up on your linear algebra for this)</li> <li>Neural Networks and DL (Basics of ML)</li> <li>Post this, I would like to introduce you to some concepts in computer vision (such as camera matrices, key-point descriptors, multi-view geometry, etc.), take you into larger networks such as CNNs &amp; Transformers, and SLAM.</li> </ol> <hr/> <h3 id="installing-ros">Installing ROS</h3> <ol> <li>Set up dual boot with Ubuntu 20.04 (make sure the version matches).</li> <li>Install ROS following the instructions for <a href="https://wiki.ros.org/noetic/Installation/Ubuntu">Noetic</a>. <ul> <li>If you’re adventurous, try Zorin OS. Its installation is similar to Ubuntu.</li> </ul> </li> <li>For a modern approach, consider Docker. While dual booting is recommended for ROS, Docker is a valuable and intriguing tool worth exploring. <ul> <li><a href="https://roboticseabass.com/2021/04/21/docker-and-ros/">Resource 1</a></li> <li><a href="https://www.reddit.com/r/ROS/comments/19d3fgk/running_ros_in_docker_pros_and_cons/">Resource 2</a></li> </ul> </li> </ol> <h2 id="week-2-getting-started-with-ros">Week 2: getting started with ROS</h2> <h3 id="a-very-very-gentle-introduction">A very, very gentle introduction</h3> <p>Check <a href="https://app.theconstruct.ai/courses/">this</a> out. Find the “ROS Basics in 5 Days” course (choose either C++ or Python) - this course isn’t entirely free, but the parts that are very nicely explain the fundamental uses (and quirks) of ROS.</p> <h3 id="reading-the-docs">Reading the docs</h3> <p>Familiarize yourself with the official <a href="https://wiki.ros.org/noetic">ROS Noetic documentation</a>. Read</p> <ul> <li><a href="https://wiki.ros.org/ROS/Introduction">The introduction</a>, and,</li> <li><a href="https://wiki.ros.org/ROS/Tutorials">The Beginner Tutorials</a>: Complete “1.1 Beginner Level” and up to “5 Defining Custom Messages” in the “1.2 Intermediate Level” section.</li> </ul> <p>While doing this, you should be putting a particular emphasis on <em>topics</em>, <em>services</em> and <em>visualization tools</em>.</p> <h2 id="week-2-the-next-bits---gazebo">Week 2: The next bits - Gazebo</h2> <ol> <li>Install and read about Gazebo from the <a href="https://classic.gazebosim.org/tutorials?cat=guided_b&amp;tut=guided_b1">Guided B Tutorials</a>.</li> <li>From the <a href="https://classic.gazebosim.org/tutorials?cat=get_started">Getting Started page</a>, explore: <ul> <li>Quick Start</li> <li>Gazebo Components</li> <li>Gazebo Architecture</li> </ul> </li> <li>Build a robot model (<a href="https://classic.gazebosim.org/tutorials?tut=build_robot&amp;cat=build_robot">Tutorial</a>)</li> <li>Add a sensor to the robot (<a href="https://classic.gazebosim.org/tutorials?tut=add_laser&amp;cat=build_robot">Tutorial</a>)</li> <li>Attempt this project: <a href="https://www.youtube.com/watch?v=594Gmkdo-_s">YouTube Tutorial</a> <ul> <li>Use LLMs (e.g., Perplexity) to convert ROS2 commands to ROS-compatible ones.</li> <li>Download project files from the video description.</li> </ul> </li> </ol> <h2 id="weeks-3-and-4-mlllll">Weeks 3 and 4: MLLLLL</h2> <h3 id="essential-reading">Essential Reading</h3> <ol> <li><a href="https://www.lesswrong.com/posts/qE73pqxAZmeACsAdF/a-short-introduction-to-machine-learning">A Short Introduction to Machine Learning</a> <ul> <li>I highly recommend this, given my affinity for LessWrong’s content.</li> </ul> </li> <li><a href="https://mml-book.github.io/">Mathematics for Machine Learning</a> <ul> <li>Quickly review the linear algebra sections before diving into the rest of the book.</li> <li>Linear algebra is incredibly cool—not just for ML, but also for robotics! Concepts like transformations, projections, and matrix factorizations are the backbone of everything from optimizing neural networks to understanding camera geometry in robotics. A strong foundation in linear algebra, optimization, and related math ensures you’re well-equipped to tackle complex problems in both fields.</li> </ul> </li> </ol> <p>How much time should it take you?</p> <ul> <li>Brief review: 2-3 days</li> <li>In-depth study: 2 weeks (2 hours daily)</li> </ul> <h4 id="next-steps">Next Steps</h4> <p>Once you’ve completed this, reach out to begin with PyTorch. This book forms the foundation for understanding ML, so take it seriously.</p>]]></content><author><name></name></author><category term="robotics"/><category term="IIIT"/><category term="robotics"/><summary type="html"><![CDATA[My introduction to robotics for a few undergrad freshmen]]></summary></entry></feed>